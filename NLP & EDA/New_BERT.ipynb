{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvP2ID5myyYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authentication for loading data from Google Drive\n",
        "# Import packages\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "from os import path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3d_Ba3cy2td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate User\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "auth_drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XuECRkyy4VL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "233ac3a9-9c4e-405d-808d-53051411a610"
      },
      "source": [
        "DRIVE_PATH = '/content/drive'\n",
        "drive.mount(DRIVE_PATH)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-YtEkGBy9KH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = path.join(DRIVE_PATH, 'My Drive', 'LinkedIn_Articles', 'Datasets', 'Twitter_Real_or_Not')\n",
        "OUTPUT_PATH = path.join(DRIVE_PATH, 'My Drive', 'LinkedIn_Articles', 'NLP & EDA')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKPAqZllzCS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0767f3ae-78db-4721-a0c3-9ba9d31b25e1"
      },
      "source": [
        "!pip install bert-for-tf2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.5)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkVWgQOXzIwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "from keras import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Fj7IVJzU6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(path.join(DATA_PATH, 'train_cleaned.csv'), index_col='id')\n",
        "df_test = pd.read_csv(path.join(DATA_PATH, 'test_cleaned.csv'), index_col='id')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oUSOsoEMFDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 256"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFFhg2wczZTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_wwm_cased_L-24_H-1024_A-16/2', trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ9lM5mozpsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4df8ce87-a1c8-4d32-a71f-e5967af2df47"
      },
      "source": [
        "tokenizer.tokenize(df_train['text_cleaned'].iloc[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Our',\n",
              " 'Dee',\n",
              " '##ds',\n",
              " 'are',\n",
              " 'the',\n",
              " 'Reason',\n",
              " 'of',\n",
              " 'this',\n",
              " '#',\n",
              " 'earthquake',\n",
              " 'May',\n",
              " 'AL',\n",
              " '##LA',\n",
              " '##H',\n",
              " 'For',\n",
              " '##gi',\n",
              " '##ve',\n",
              " 'us',\n",
              " 'all']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmwRW6kmzzwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "cd8f4f29-1973-4edb-e511-afc40bcefed4"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df_train['text_cleaned'].iloc[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3458,\n",
              " 9115,\n",
              " 3680,\n",
              " 1132,\n",
              " 1103,\n",
              " 21642,\n",
              " 1104,\n",
              " 1142,\n",
              " 108,\n",
              " 8386,\n",
              " 1318,\n",
              " 18589,\n",
              " 10783,\n",
              " 3048,\n",
              " 1370,\n",
              " 5389,\n",
              " 2707,\n",
              " 1366,\n",
              " 1155]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cReqvifMz_8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def tokenize_tweets(tweet):\n",
        "  # return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweet))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvPPg_931cx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ids = [tokenize_tweets(tweet) for tweet in df_train['text_cleaned']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKsDF4IP1so2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8caaf30c-915f-4b64-f005-932ab95bf0f9"
      },
      "source": [
        "# train_ids[1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4089, 1783, 1485, 2001, 6413, 2176, 17784, 5276, 119, 1803]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40sRkwFMLrIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_tweets(tweets, max_len=MAX_LEN):\n",
        "  tokens = []\n",
        "  masks = []\n",
        "  segments = []\n",
        "\n",
        "  for tweet in tweets:\n",
        "    tweet = tokenizer.tokenize(tweet)\n",
        "    tweet = tweet[:max_len - 2]\n",
        "    input_seq = ['[CLS]'] + tweet + ['[SEP]']\n",
        "\n",
        "    pad_seq = max_len - len(input_seq)\n",
        "\n",
        "    token = tokenizer.convert_tokens_to_ids(input_seq)\n",
        "    token += [0] * pad_seq\n",
        "    \n",
        "    mask = [1] * len(input_seq) + [0] * pad_seq\n",
        "\n",
        "    segment = [0] * max_len\n",
        "\n",
        "    tokens.append(token)\n",
        "    masks.append(mask)\n",
        "    segments.append(segment)\n",
        "\n",
        "  return np.array(tokens), np.array(masks), np.array(segments)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTE04wJ8Q9n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_encoded = encode_tweets(df_train['text_cleaned'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VuRZDMHRXHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_encoded = encode_tweets(df_test['text_cleaned'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kokR6yz4NlWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_bert_model(max_seq_length=MAX_LEN):\n",
        "  input_word_ids = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "  input_mask = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "  segment_ids = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "  bert_output = sequence_output[:, 0, :]\n",
        "\n",
        "  additional_layers = layers.Reshape((1, 1024))(bert_output)\n",
        "  # additional_layers = layers.LSTM(300, return_sequences=True)(additional_layers)\n",
        "  # additional_layers = layers.LSTM(200, return_sequences=True)(additional_layers)\n",
        "  additional_layers = layers.LSTM(10, return_sequences=True)(additional_layers)\n",
        "  additional_layers = layers.LSTM(10)(additional_layers)\n",
        "  additional_layers = layers.Dense(1, activation='sigmoid')(additional_layers)\n",
        "\n",
        "  model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=additional_layers)\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=0.001), metrics=['accuracy'], loss=binary_crossentropy)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdo5b2r31sf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = build_bert_model()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUBWmevn1sbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "8edb09d0-ec90-4ae9-e038-d6cf9c24aeda"
      },
      "source": [
        "nn.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 1024), (None 333579265   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 1024)]       0           keras_layer[2][1]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1, 1024)      0           tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 1, 10)        41400       reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 10)           840         lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            11          lstm_7[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 333,621,516\n",
            "Trainable params: 42,251\n",
            "Non-trainable params: 333,579,265\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g002a2tiRiG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f6e127e-a593-45f8-de7e-ebf7b6488db7"
      },
      "source": [
        "nn.fit(train_encoded, df_train['target'], validation_split=0.2, epochs=5, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOZBhnw_1sS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_target = nn.predict_classes(test_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmIv1Dpp1sOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_target.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ao9SHHv1sE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'id': df_test.index, 'target': test_target.flatten()})\n",
        "submission.to_csv(path.join(DATA_PATH, 'submission_bert.csv'), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}